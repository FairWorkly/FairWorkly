"""LLM Provider factory that reads defaults from config/environment."""

import os
from typing import Optional, List, Dict, Any

from master_agent.config import load_config
from .provider_base import LLMProviderBase
from .langchain_provider import LangChainOpenAIProvider
from .local_provider import LocalHuggingFaceProvider


class LLMProviderFactory:
    """
    Factory to create the right LLM provider
    """

    @staticmethod
    def create(provider_type: Optional[str] = None) -> LLMProviderBase:
        """
        Create LLM provider based on config
        """
        config = load_config()
        model_params = config.get("model_params", {})
        default_provider = model_params.get("deployment_mode_llm", "online")
        provider_env = os.getenv("LLM_PROVIDER")
        provider_type = (provider_type or provider_env or default_provider or "").lower()

        if provider_type in {"online", "openai"}:
            model = model_params.get("online_model_name") or os.getenv("OPENAI_MODEL")
            if not model:
                raise ValueError(
                    "OpenAI model name is not configured. Set model_params.online_model_name "
                    "or the OPENAI_MODEL environment variable."
                )
            api_base = model_params.get("openai_api_base") or os.getenv("OPENAI_API_BASE")
            temperature = model_params.get("temperature")
            return LangChainOpenAIProvider(model=model, api_base=api_base, temperature=temperature)

        if provider_type == "local":
            return LocalHuggingFaceProvider(config)

        raise ValueError(f"Unknown provider type: {provider_type}")


class LLMProvider:
    """Simple wrapper that delegates to the factory."""

    def __init__(self):
        self.provider = LLMProviderFactory.create()

    async def generate(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: int = 4096
    ) -> Dict[str, Any]:
        return await self.provider.generate(messages, temperature, max_tokens)
